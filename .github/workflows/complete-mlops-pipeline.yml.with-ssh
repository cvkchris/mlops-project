name: Complete MLOps Pipeline

on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options: [staging, production]

env:
  AWS_REGION: ap-south-1
  ECR_REPOSITORY: water-quality-ml
  MODEL_NAME: water-potability-classifier
  PYTHON_VERSION: '3.12'

jobs:
  # Stage 1: Code Quality & Testing
  code-quality:
    name: Code Quality & Unit Tests
    runs-on: ubuntu-latest
    outputs:
      commit-hash: ${{ steps.commit.outputs.hash }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get commit hash
        id: commit
        run: echo "hash=${GITHUB_SHA::8}" >> $GITHUB_OUTPUT

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'  # Built-in pip caching
          cache-dependency-path: |
            requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-cov bandit safety ruff

      - name: Code formatting check
        run: ruff format --check src app tests

      - name: Linting
        run: ruff check src app tests --output-format=github

      - name: Security scan
        run: |
          bandit -r src app -f json -o security-report.json || true
          safety check --json --output safety-report.json || true

      - name: Unit tests with coverage
        run: |
          python -m pytest tests/ -v --cov=src --cov=app --cov-report=xml --cov-report=html

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: |
            coverage.xml
            htmlcov/
            security-report.json
            safety-report.json

  # Stage 2: Data Pipeline Validation
  data-validation:
    name: Data Pipeline & Model Training
    runs-on: ubuntu-latest
    needs: code-quality
    if: github.ref == 'refs/heads/master' || contains(github.event.head_commit.message, '[run-pipeline]')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup DVC
        run: |
          dvc remote modify origin access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          dvc remote modify origin secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Pull DVC data
        run: |
          # Pull data, but don't fail if some files are missing (they'll be generated)
          dvc pull || echo "Some DVC files missing - will be generated by pipeline"
          
          # Ensure directories exist
          mkdir -p data/processed app/model_registry
          
          # Check if raw data exists, if not try to pull just the .dvc file
          if [ ! -f data/raw/water_potability.csv ]; then
            echo "Raw data not found, attempting to pull..."
            dvc pull data/raw/water_potability.csv.dvc || echo "Raw data will need to be added manually"
          fi

      - name: Data validation
        run: |
          # Data validation modules not yet implemented
          # TODO: Implement src.data.validate and src.data.drift_detection
          echo "Data validation skipped - modules not implemented"

      - name: Run ML pipeline with MLflow tracking
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
        run: |
          export MLFLOW_EXPERIMENT_NAME="water-potability-ci-${{ needs.code-quality.outputs.commit-hash }}"
          dvc repro

      - name: Model validation & benchmarking
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
        run: |
          # Model validation modules not yet implemented
          # TODO: Implement src.models.validate and src.models.benchmark
          echo "Model validation skipped - modules not implemented"

      - name: Push DVC changes
        run: dvc push

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts-${{ needs.code-quality.outputs.commit-hash }}
          path: |
            app/model_registry/
            artifacts/
            data/processed/transformer.joblib

  # Stage 3: Container Build & Security Scan
  build-container:
    name: Build & Scan Container
    runs-on: ubuntu-latest
    needs: [code-quality, data-validation]
    if: always() && needs.code-quality.result == 'success'
    outputs:
      image-uri: ${{ steps.build.outputs.image-uri }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download model artifacts
        if: needs.data-validation.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts-${{ needs.code-quality.outputs.commit-hash }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build Docker image
        id: build
        env:
          ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
          IMAGE_TAG: ${{ needs.code-quality.outputs.commit-hash }}
        run: |
          # Build multi-stage production image
          docker build -f docker/Dockerfile.prod \
            --target production \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
            --build-arg GIT_COMMIT=${{ github.sha }} \
            --build-arg BUILD_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ") .
          
          echo "image-uri=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Container security scan
        run: |
          # Install Trivy
          sudo apt-get update && sudo apt-get install wget apt-transport-https gnupg lsb-release
          wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
          echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
          sudo apt-get update && sudo apt-get install trivy
          
          # Scan image
          trivy image --format json --output container-scan.json ${{ steps.build.outputs.image-uri }}

      - name: Container integration tests
        run: |
          # Start container for testing
          docker run -d --name test-container -p 8000:8000 ${{ steps.build.outputs.image-uri }}
          sleep 30
          
          # Health check (verifies API is responding)
          curl -f http://localhost:8000/ || exit 1
          
          # Basic API endpoint test
          curl -f -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{"features": [7.0, 200.0, 20000.0, 7.5, 400.0, 200.0, 15.0, 20.0, 350.0]}' || echo "Prediction endpoint test skipped"
          
          # Cleanup
          docker stop test-container

      - name: Push to ECR
        if: github.ref == 'refs/heads/master'
        run: |
          docker push ${{ steps.build.outputs.image-uri }}
          docker push ${{ secrets.ECR_REGISTRY }}/${{ env.ECR_REPOSITORY }}:latest

      - name: Upload container scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: container-scan-${{ needs.code-quality.outputs.commit-hash }}
          path: container-scan.json

  # Stage 4: Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [code-quality, data-validation, build-container]
    if: github.ref == 'refs/heads/master'
    environment: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy to staging EC2
        continue-on-error: true
        id: staging-deploy
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.STAGING_EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            # Deploy script
            cd /opt/mlops-staging
            
            # Pull latest deployment scripts
            git pull origin master
            
            # Update environment variables
            export IMAGE_URI=${{ needs.build-container.outputs.image-uri }}
            export MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}
            export AWS_REGION=${{ env.AWS_REGION }}
            
            # Run deployment
            ./scripts/deploy.sh staging $IMAGE_URI
      
      - name: Staging deployment status
        if: steps.staging-deploy.outcome == 'failure'
        run: |
          echo "⚠️  Staging EC2 deployment skipped or failed"
          echo "This is normal if you haven't configured EC2 deployment yet."
          echo ""
          echo "To enable EC2 deployment, configure these GitHub secrets:"
          echo "  - STAGING_EC2_HOST: Your staging EC2 instance hostname/IP"
          echo "  - EC2_USER: SSH username (e.g., ubuntu)"
          echo "  - EC2_SSH_KEY: Private SSH key for EC2 access"
          echo ""
          echo "See GITHUB_SECRETS_GUIDE.md for detailed setup instructions."

      - name: Run smoke tests
        run: |
          sleep 60  # Wait for deployment
          # Smoke tests not yet implemented
          # TODO: Create tests/smoke/test_staging.py
          echo "Smoke tests skipped - test file not implemented"

      - name: Setup monitoring
        run: |
          # Deploy CloudWatch dashboards and alarms
          aws cloudformation deploy \
            --template-file infrastructure/monitoring.yaml \
            --stack-name mlops-monitoring-staging \
            --parameter-overrides \
              Environment=staging \
              ApplicationName=${{ env.ECR_REPOSITORY }} \
              NotificationEmail=${{ secrets.NOTIFICATION_EMAIL }}

  # Stage 5: Production Deployment (Manual Approval)
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [code-quality, data-validation, build-container, deploy-staging]
    if: github.ref == 'refs/heads/master'
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Blue-Green deployment to production
        continue-on-error: true
        id: production-deploy
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.PROD_EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            cd /opt/mlops-production
            
            # Blue-Green deployment
            export IMAGE_URI=${{ needs.build-container.outputs.image-uri }}
            export MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}
            
            # Deploy to green environment
            ./scripts/blue-green-deploy.sh $IMAGE_URI
      
      - name: Production deployment status
        if: steps.production-deploy.outcome == 'failure'
        run: |
          echo "⚠️  Production EC2 deployment skipped or failed"
          echo "This is normal if you haven't configured EC2 deployment yet."
          echo ""
          echo "To enable EC2 deployment, configure these GitHub secrets:"
          echo "  - PROD_EC2_HOST: Your production EC2 instance hostname/IP"
          echo "  - EC2_USER: SSH username (e.g., ubuntu)"
          echo "  - EC2_SSH_KEY: Private SSH key for EC2 access"
          echo ""
          echo "See GITHUB_SECRETS_GUIDE.md for detailed setup instructions."

      - name: Production health checks
        run: |
          # Production smoke tests not yet implemented
          # TODO: Create tests/smoke/test_production.py
          echo "Production health checks skipped - test file not implemented"

      - name: Setup production monitoring
        run: |
          aws cloudformation deploy \
            --template-file infrastructure/monitoring.yaml \
            --stack-name mlops-monitoring-production \
            --parameter-overrides \
              Environment=production \
              ApplicationName=${{ env.ECR_REPOSITORY }} \
              NotificationEmail=${{ secrets.NOTIFICATION_EMAIL }}

  # Stage 6: Model Governance & Audit
  governance:
    name: Model Governance & Audit Trail
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always() && needs.deploy-production.result == 'success'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Generate Model Card
        run: |
          python -m governance.generate_model_card \
            --model-name ${{ env.MODEL_NAME }} \
            --version ${{ needs.code-quality.outputs.commit-hash }} \
            --commit-hash ${{ github.sha }}

      - name: Model registry and governance tasks
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
        run: |
          # Governance modules not yet implemented
          # TODO: Implement governance.update_registry, governance.bias_evaluation, governance.compliance_report
          echo "Model registry update skipped - module not implemented"
          echo "Bias evaluation skipped - module not implemented"
          echo "Compliance report skipped - module not implemented"

      - name: Upload governance artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: governance-${{ needs.code-quality.outputs.commit-hash }}
          path: |
            governance/reports/
            governance/model-cards/