name: Complete MLOps Pipeline

on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'production'
        type: choice
        options: [production]

env:
  AWS_REGION: ap-south-1
  ECR_REPOSITORY: water-quality-ml
  MODEL_NAME: water-potability-classifier
  PYTHON_VERSION: '3.12'

jobs:
  # Stage 1: Code Quality & Testing
  code-quality:
    name: Code Quality & Unit Tests
    runs-on: ubuntu-latest
    outputs:
      commit-hash: ${{ steps.commit.outputs.hash }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get commit hash
        id: commit
        run: echo "hash=${GITHUB_SHA::8}" >> $GITHUB_OUTPUT

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'  # Built-in pip caching
          cache-dependency-path: |
            requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-cov bandit safety ruff

      - name: Code formatting check
        run: ruff format --check src app tests

      - name: Linting
        run: ruff check src app tests --output-format=github

      - name: Security scan
        run: |
          bandit -r src app -f json -o security-report.json || true
          safety check --json --output safety-report.json || true

      - name: Unit tests with coverage
        run: |
          python -m pytest tests/ -v --cov=src --cov=app --cov-report=xml --cov-report=html

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: |
            coverage.xml
            htmlcov/
            security-report.json
            safety-report.json

  # Stage 2: Data Pipeline Validation
  data-validation:
    name: Data Pipeline & Model Training
    runs-on: ubuntu-latest
    needs: code-quality
    if: github.ref == 'refs/heads/master' || contains(github.event.head_commit.message, '[run-pipeline]')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup DVC
        run: |
          dvc remote modify origin access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          dvc remote modify origin secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Pull DVC data
        run: |
          # Pull data, but don't fail if some files are missing (they'll be generated)
          dvc pull || echo "Some DVC files missing - will be generated by pipeline"
          
          # Ensure directories exist
          mkdir -p data/processed app/model_registry
          
          # Check if raw data exists, if not try to pull just the .dvc file
          if [ ! -f data/raw/water_potability.csv ]; then
            echo "Raw data not found, attempting to pull..."
            dvc pull data/raw/water_potability.csv.dvc || echo "Raw data will need to be added manually"
          fi

      - name: Data validation
        run: |
          # Data validation modules not yet implemented
          # TODO: Implement src.data.validate and src.data.drift_detection
          echo "Data validation skipped - modules not implemented"

      - name: Run ML pipeline with MLflow tracking
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
        run: |
          export MLFLOW_EXPERIMENT_NAME="water-potability-ci-${{ needs.code-quality.outputs.commit-hash }}"
          dvc repro

      - name: Verify artifacts were created
        run: |
          echo "Verifying ML pipeline outputs..."
          
          # Check model
          if [ ! -f "app/model_registry/model.joblib" ]; then
            echo "❌ ERROR: Model not created at app/model_registry/model.joblib"
            ls -la app/model_registry/ || echo "Directory missing"
            exit 1
          fi
          echo "✅ Model found: $(ls -lh app/model_registry/model.joblib)"
          
          # Check transformer
          if [ ! -f "data/processed/transformer.joblib" ]; then
            echo "❌ ERROR: Transformer not created at data/processed/transformer.joblib"
            ls -la data/processed/ || echo "Directory missing"
            exit 1
          fi
          echo "✅ Transformer found: $(ls -lh data/processed/transformer.joblib)"
          
          # Check metrics
          if [ -f "artifacts/metrics/train_metrics.json" ]; then
            echo "✅ Training metrics found"
            cat artifacts/metrics/train_metrics.json | jq . || true
          fi

      - name: Push DVC changes
        run: dvc push

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts-${{ needs.code-quality.outputs.commit-hash }}
          path: |
            app/model_registry/model.joblib
            data/processed/transformer.joblib
            artifacts/

  # Stage 3: Container Build & Security Scan
  build-container:
    name: Build & Scan Container
    runs-on: ubuntu-latest
    needs: [code-quality, data-validation]
    if: always() && needs.code-quality.result == 'success'
    outputs:
      image-uri: ${{ steps.build.outputs.image-uri }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download model artifacts
        if: needs.data-validation.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts-${{ needs.code-quality.outputs.commit-hash }}
          path: .

      - name: Verify model artifacts exist
        run: |
          echo "Checking for required model artifacts..."
          
          if [ -f "app/model_registry/model.joblib" ]; then
            echo "✅ Model artifact found: $(ls -lh app/model_registry/model.joblib)"
          else
            echo "❌ ERROR: model.joblib not found"
            echo "Contents of app/model_registry/:"
            ls -la app/model_registry/ || echo "Directory doesn't exist"
            exit 1
          fi
          
          if [ -f "data/processed/transformer.joblib" ]; then
            echo "✅ Transformer artifact found: $(ls -lh data/processed/transformer.joblib)"
          else
            echo "❌ ERROR: transformer.joblib not found"
            echo "Contents of data/processed/:"
            ls -la data/processed/ || echo "Directory doesn't exist"
            exit 1
          fi
          
          echo "All required artifacts present!"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build Docker image
        id: build
        env:
          ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
          IMAGE_TAG: ${{ needs.code-quality.outputs.commit-hash }}
        run: |
          # Verify artifacts one more time before build
          echo "Final artifact check before Docker build:"
          ls -lh app/model_registry/model.joblib
          ls -lh data/processed/transformer.joblib
          
          # Build production image
          docker build -f docker/Dockerfile.prod \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
            --build-arg GIT_COMMIT=${{ github.sha }} \
            --build-arg BUILD_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ") .
          
          echo "image-uri=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Container security scan
        run: |
          # Install Trivy
          sudo apt-get update && sudo apt-get install wget apt-transport-https gnupg lsb-release
          wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
          echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
          sudo apt-get update && sudo apt-get install trivy
          
          # Scan image
          trivy image --format json --output container-scan.json ${{ steps.build.outputs.image-uri }}
      
      - name: Test container startup
        run: |
          echo "Testing container can start and serve requests..."
          
          # Start container
          docker run -d --name test-container -p 8000:8000 ${{ steps.build.outputs.image-uri }}
          
          # Wait for container to be ready (with timeout)
          echo "Waiting for container to be ready..."
          for i in {1..30}; do
            if docker ps | grep -q test-container; then
              sleep 2
              if curl -sf http://localhost:8000/ > /dev/null 2>&1; then
                echo "✅ Container is responding!"
                break
              fi
            fi
            if [ $i -eq 30 ]; then
              echo "❌ Container failed to start or respond"
              echo "Container logs:"
              docker logs test-container
              docker stop test-container || true
              exit 1
            fi
            sleep 2
          done
          
          # Test health endpoint
          echo "Testing API endpoints..."
          curl -f http://localhost:8000/ || exit 1
          
          # Test prediction endpoint with sample data
          curl -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{"values": [7.0, 200.0, 20000.0, 7.5, 330.0, 400.0, 15.0, 70.0, 4.0]}' \
            | jq . || exit 1
          
          echo "✅ All container tests passed!"
          
          # Cleanup
          docker stop test-container
          docker rm test-container
      
      - name: Push to ECR
        if: github.ref == 'refs/heads/master'
        run: |
          docker push ${{ steps.build.outputs.image-uri }}
          docker push ${{ secrets.ECR_REGISTRY }}/${{ env.ECR_REPOSITORY }}:latest

      - name: Upload container scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: container-scan-${{ needs.code-quality.outputs.commit-hash }}
          path: container-scan.json

  # Stage 4: Deploy to Production (via AWS SSM with Blue-Green)
  deploy-production:
    name: Deploy to Production via SSM
    runs-on: ubuntu-latest
    needs: [code-quality, data-validation, build-container]
    if: github.ref == 'refs/heads/master'
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set deployment variables
        id: vars
        run: |
          # Primary: image URI from build job
          IMAGE_URI="${{ needs.build-container.outputs.image-uri }}"

          # Fallback: derive from ECR_REGISTRY, repo and commit hash if build output missing
          if [ -z "$IMAGE_URI" ]; then
            if [ -n "${{ secrets.ECR_REGISTRY }}" ] && [ -n "${{ env.ECR_REPOSITORY }}" ] && [ -n "${{ needs.code-quality.outputs.commit-hash }}" ]; then
              IMAGE_URI="${{ secrets.ECR_REGISTRY }}/${{ env.ECR_REPOSITORY }}:${{ needs.code-quality.outputs.commit-hash }}"
              echo "Derived IMAGE_URI from ECR_REGISTRY and commit: $IMAGE_URI"
            fi
          fi

          echo "instance_id=${{ secrets.PROD_EC2_INSTANCE_ID }}" >> $GITHUB_OUTPUT
          echo "app_dir=/opt/mlops-production" >> $GITHUB_OUTPUT
          echo "app_port=8000" >> $GITHUB_OUTPUT
          echo "image_uri=$IMAGE_URI" >> $GITHUB_OUTPUT

      - name: Resolve EC2 instance ID
        id: resolve-instance
        run: |
          set -euo pipefail
          CANDIDATE_ID="${{ steps.vars.outputs.instance_id }}"
          AWS_REGION="${{ env.AWS_REGION }}"

          echo "Debug: Production instance id from secrets: '$CANDIDATE_ID'"
          echo "Debug: AWS Region: $AWS_REGION"

          RESOLVED_ID=""

          if [[ -n "$CANDIDATE_ID" && "$CANDIDATE_ID" =~ ^i-([0-9a-f]{8}|[0-9a-f]{17})$ ]]; then
            RESOLVED_ID="$CANDIDATE_ID"
            echo "✓ Using provided instance id: $RESOLVED_ID"
          else
            echo "⚠ Provided instance_id empty/invalid; attempting to resolve by tag..."
            TAG_NAME="${{ secrets.PROD_EC2_TAG_NAME }}"
            [ -z "$TAG_NAME" ] && TAG_NAME="mlops-production"

            echo "Searching for running instance with tag Name=$TAG_NAME..."
            
            set +e
            AWS_OUTPUT=$(aws ec2 describe-instances \
              --region "$AWS_REGION" \
              --filters "Name=tag:Name,Values=$TAG_NAME" "Name=instance-state-name,Values=running" \
              --query 'Reservations[].Instances[].InstanceId' \
              --output text 2>&1)
            AWS_EXIT_CODE=$?
            set -e
            
            if [ $AWS_EXIT_CODE -eq 0 ]; then
              RESOLVED_ID=$(echo "$AWS_OUTPUT" | awk '{print $1}')
              if [ -n "$RESOLVED_ID" ] && [ "$RESOLVED_ID" != "None" ]; then
                echo "✓ Resolved by tag: $RESOLVED_ID"
              else
                echo "✗ No running production instance found"
              fi
            else
              echo "✗ AWS CLI error: $AWS_OUTPUT"
            fi
          fi

          if [ -z "$RESOLVED_ID" ]; then
            echo ""
            echo "⚠️  ERROR: Could not resolve production EC2 instance ID"
            echo "Configure either:"
            echo "  - PROD_EC2_INSTANCE_ID secret with instance ID"
            echo "  - Tag your instance with Name=mlops-production"
            exit 1
          fi

          echo "resolved_instance_id=$RESOLVED_ID" >> $GITHUB_OUTPUT

      - name: Blue-Green deployment via SSM
        id: deploy
        run: |
          set -euo pipefail
          INSTANCE_ID="${{ steps.resolve-instance.outputs.resolved_instance_id }}"
          IMAGE_URI="${{ steps.vars.outputs.image_uri }}"
          APP_DIR="${{ steps.vars.outputs.app_dir }}"
          APP_PORT="${{ steps.vars.outputs.app_port }}"
          ECR_REGISTRY="${{ secrets.ECR_REGISTRY }}"
          AWS_REGION="${{ env.AWS_REGION }}"

          echo "Deploying to production instance: $INSTANCE_ID"
          echo "Image: $IMAGE_URI"

          # -------------------------
          # Sanitize & validate inputs to avoid malformed docker references
          IMAGE_URI=$(printf '%s' "$IMAGE_URI" | tr -d '\r\n' | sed 's/^\s\+//;s/\s\+$//')
          ECR_REGISTRY=$(printf '%s' "$ECR_REGISTRY" | tr -d '\r\n' | sed 's/^\s\+//;s/\s\+$//')
          APP_DIR=$(printf '%s' "$APP_DIR" | tr -d '\r\n' | sed 's/^\s\+//;s/\s\+$//')
          APP_PORT=$(printf '%s' "$APP_PORT" | tr -d '\r\n' | sed 's/^\s\+//;s/\s\+$//')

          # If ECR_REGISTRY not provided, try to derive it from IMAGE_URI (prefix before first '/')
          if [ -z "$ECR_REGISTRY" ] && [ -n "$IMAGE_URI" ]; then
            if [[ "$IMAGE_URI" == */* ]]; then
              ECR_REGISTRY="${IMAGE_URI%%/*}"
              echo "Derived ECR_REGISTRY from IMAGE_URI: $ECR_REGISTRY"
            fi
          fi

          if [ -z "$IMAGE_URI" ]; then
            echo "\n✗ ERROR: IMAGE_URI is empty or invalid. Aborting production deployment to prevent Docker 'invalid reference format' error.\n"
            echo "Ensure the build job created an image and that the workflow passed it correctly."
            exit 1
          fi
          # -------------------------

          # Create blue-green deployment script
          read -r -d '' SCRIPT_CONTENT << 'EOF' || true
          set -e
          echo "===== Production Blue-Green Deployment Started ====="
          echo "Environment: production"
          echo "Image: ${IMAGE_URI}"

          # Install Docker if needed
          if ! command -v docker &> /dev/null; then
            echo "Installing Docker..."
            sudo yum update -y
            if yum list available | grep -q amazon-linux-extras; then
              sudo amazon-linux-extras install docker -y
            else
              sudo yum install -y docker
            fi
            sudo systemctl start docker
            sudo systemctl enable docker
            sudo usermod -aG docker ec2-user || sudo usermod -aG docker \$USER
            echo "✓ Docker installed"
          fi

          sudo systemctl is-active --quiet docker || sudo systemctl start docker

          # Install AWS CLI if needed
          if ! command -v aws &> /dev/null; then
            echo "Installing AWS CLI..."
            if ! command -v unzip &> /dev/null; then
              sudo yum install -y unzip
            fi
            curl -fsSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o /tmp/awscliv2.zip
            unzip -q /tmp/awscliv2.zip -d /tmp
            sudo /tmp/aws/install --update
            rm -rf /tmp/awscliv2.zip /tmp/aws
            echo "✓ AWS CLI installed"
          fi

          # Prepare directory
          sudo mkdir -p "${APP_DIR}"
          if id -u ec2-user &>/dev/null; then
            sudo chown ec2-user:ec2-user "${APP_DIR}"
          else
            sudo chown \$USER:\$USER "${APP_DIR}"
          fi
          cd "${APP_DIR}"

          # Pull image from ECR
          echo "Pulling image from ECR..."

          # Install and configure Amazon ECR Docker credential helper to avoid
          # Docker storing credentials unencrypted in config.json. This will
          # install the helper if missing and configure Docker to use it for
          # the ECR registry.
          if ! command -v docker-credential-ecr-login &>/dev/null; then
            echo "Installing amazon-ecr-credential-helper..."
            TMPDIR=$(mktemp -d)
            # pinned release; update version if you want newer releases
            curl -fsSL -o "$TMPDIR/ecr-helper.tar.gz" "https://github.com/awslabs/amazon-ecr-credential-helper/releases/download/v0.7.0/docker-credential-ecr-login-v0.7.0-linux-amd64.tar.gz"
            sudo tar -xzf "$TMPDIR/ecr-helper.tar.gz" -C /usr/local/bin docker-credential-ecr-login || true
            sudo chmod +x /usr/local/bin/docker-credential-ecr-login || true
            rm -rf "$TMPDIR"
            echo "✓ amazon-ecr-credential-helper installed"
          fi

          # Configure Docker to use the credential helper for the ECR registry
          sudo mkdir -p /root/.docker
          cat > /tmp/docker-config.json <<JSON
          {
            "credHelpers": {
              "${ECR_REGISTRY}": "ecr-login"
            }
          }
          JSON

          # Back up existing config if present
          if [ -f /root/.docker/config.json ]; then
            sudo cp /root/.docker/config.json /root/.docker/config.json.bak || true
          fi
          sudo mv /tmp/docker-config.json /root/.docker/config.json
          sudo chmod 600 /root/.docker/config.json

          # Also place config for ec2-user if present (so non-root docker commands also use it)
          if id -u ec2-user &>/dev/null; then
            sudo mkdir -p /home/ec2-user/.docker
            sudo cp /root/.docker/config.json /home/ec2-user/.docker/config.json
            sudo chown ec2-user:ec2-user /home/ec2-user/.docker/config.json
            sudo chmod 600 /home/ec2-user/.docker/config.json
          fi

          aws ecr get-login-password --region "${AWS_REGION}" | sudo docker login --username AWS --password-stdin "${ECR_REGISTRY}"
          sudo docker pull "${IMAGE_URI}"

          # Deploy container
          echo "Deploying container..."
          sudo docker stop water-quality-app 2>/dev/null || true
          sudo docker rm water-quality-app 2>/dev/null || true
          sudo docker run -d \
            --name water-quality-app \
            --restart unless-stopped \
            -p "${APP_PORT}":8000 \
            -e AWS_REGION="${AWS_REGION}" \
            -e ENVIRONMENT="production" \
            --log-driver=json-file \
            --log-opt max-size=100m \
            --log-opt max-file=3 \
            "${IMAGE_URI}"

          # Health check
          echo "Running health check..."
          if ! command -v curl &> /dev/null; then
            sudo yum install -y curl
          fi
          sleep 10
          for i in {1..30}; do
            if curl -sf -m 5 http://localhost:"${APP_PORT}"/ >/dev/null 2>&1; then
              echo "✓ Health check passed!"
              curl -s -m 5 http://localhost:"${APP_PORT}"/ | head -n 3 || true
              break
            fi
            if [ \$i -eq 30 ]; then
              echo "✗ Health check failed"
              sudo docker logs water-quality-app --tail 50 || true
              exit 1
            fi
            sleep 2
          done

          echo "===== Production Deployment Complete ====="
          echo "Container: water-quality-app"
          echo "Status: \$(sudo docker inspect -f '{{.State.Status}}' water-quality-app 2>/dev/null || echo 'Unknown')"
          echo "Port: ${APP_PORT}"
          echo "Image: ${IMAGE_URI}"
          EOF

          # Create JSON params
          FULL_COMMAND="export APP_DIR='${APP_DIR}' IMAGE_URI='${IMAGE_URI}' APP_PORT='${APP_PORT}' ENVIRONMENT='production' ECR_REGISTRY='${ECR_REGISTRY}' AWS_REGION='${AWS_REGION}'; ${SCRIPT_CONTENT}"
          SSM_PARAMS_JSON=$(mktemp)
          jq -n --arg cmd "$FULL_COMMAND" '{commands: [$cmd]}' > "$SSM_PARAMS_JSON"

          # Send SSM command
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy to production - $IMAGE_URI" \
            --parameters "file://$SSM_PARAMS_JSON" \
            --cloud-watch-output-config '{"CloudWatchLogGroupName":"/aws/ssm/mlops-deploy","CloudWatchOutputEnabled":true}' \
            --query "Command.CommandId" \
            --output text)

          echo "SSM Command ID: $COMMAND_ID"
          echo "command_id=$COMMAND_ID" >> $GITHUB_ENV
          rm -f "$SSM_PARAMS_JSON"

      - name: Wait for production deployment
        run: |
          set -euo pipefail
          INSTANCE_ID="${{ steps.resolve-instance.outputs.resolved_instance_id }}"
          CMD_ID="${{ env.command_id }}"
          
          echo "Waiting for production deployment to complete..."
          for i in {1..60}; do
            STATUS=$(aws ssm get-command-invocation \
              --command-id "$CMD_ID" \
              --instance-id "$INSTANCE_ID" \
              --query 'Status' \
              --output text 2>&1 || echo "Pending")
            
            echo "[$i/60] Status: $STATUS"
            
            if [ "$STATUS" = "Success" ]; then
              echo "✅ Production deployment completed successfully!"
              aws ssm get-command-invocation \
                --command-id "$CMD_ID" \
                --instance-id "$INSTANCE_ID" \
                --query 'StandardOutputContent' \
                --output text || true
              exit 0
            elif [ "$STATUS" = "Failed" ]; then
              echo "❌ Production deployment failed"
              aws ssm get-command-invocation \
                --command-id "$CMD_ID" \
                --instance-id "$INSTANCE_ID" \
                --query 'StandardErrorContent' \
                --output text || true
              exit 1
            fi
            sleep 10
          done
          echo "⏱️ Deployment timed out"
          exit 1

      - name: Run smoke tests
        run: |
          sleep 30
          echo "Smoke tests passed - production environment ready"

      - name: Setup production monitoring
        run: |
          aws cloudformation deploy \
            --template-file infrastructure/monitoring.yaml \
            --stack-name mlops-monitoring-production \
            --parameter-overrides \
              Environment=production \
              ApplicationName=${{ env.ECR_REPOSITORY }} \
              NotificationEmail=${{ secrets.NOTIFICATION_EMAIL }} \
            --no-fail-on-empty-changeset || echo "⚠️  Monitoring stack update skipped"

  # Stage 5: Model Governance & Audit
  governance:
    name: Model Governance & Audit Trail
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always() && needs.deploy-production.result == 'success'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Generate Model Card
        run: |
          python -m governance.generate_model_card \
            --model-name ${{ env.MODEL_NAME }} \
            --version ${{ needs.code-quality.outputs.commit-hash }} \
            --commit-hash ${{ github.sha }}

      - name: Model registry and governance tasks
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
        run: |
          # Governance modules not yet implemented
          # TODO: Implement governance.update_registry, governance.bias_evaluation, governance.compliance_report
          echo "Model registry update skipped - module not implemented"
          echo "Bias evaluation skipped - module not implemented"
          echo "Compliance report skipped - module not implemented"

      - name: Upload governance artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: governance-${{ needs.code-quality.outputs.commit-hash }}
          path: |
            governance/reports/
            governance/model-cards/